# ğŸ¤– Agentæ¶æ„è®¾è®¡

## ğŸ“š æ¦‚è¿°

æ™ºèƒ½Agentæ˜¯äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ï¼Œèƒ½å¤Ÿæ„ŸçŸ¥ç¯å¢ƒã€è¿›è¡Œæ¨ç†ã€åˆ¶å®šå†³ç­–å¹¶æ‰§è¡ŒåŠ¨ä½œã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»Agentçš„æ¶æ„è®¾è®¡åŸç†å’Œå®ç°æ–¹æ³•ã€‚

## ğŸ—ï¸ AgentåŸºç¡€æ¶æ„

### æ ¸å¿ƒç»„ä»¶æ¨¡å‹
```python
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum
import asyncio
import time

class AgentState(Enum):
    """AgentçŠ¶æ€æšä¸¾"""
    IDLE = "idle"
    THINKING = "thinking"
    PLANNING = "planning"
    ACTING = "acting"
    OBSERVING = "observing"
    ERROR = "error"

@dataclass
class AgentPerception:
    """Agentæ„ŸçŸ¥ä¿¡æ¯"""
    timestamp: float
    observations: Dict[str, Any]
    confidence: float
    source: str
    metadata: Dict[str, Any] = None

@dataclass
class AgentAction:
    """AgentåŠ¨ä½œå®šä¹‰"""
    action_type: str
    parameters: Dict[str, Any]
    confidence: float
    expected_outcome: str
    timeout: float = 30.0

class BaseAgent(ABC):
    """AgentåŸºç¡€æŠ½è±¡ç±»"""

    def __init__(self, name: str, config: Dict[str, Any] = None):
        self.name = name
        self.config = config or {}
        self.state = AgentState.IDLE
        self.perception_buffer = []
        self.action_history = []
        self.goal_stack = []
        self.current_goal = None

        # åˆå§‹åŒ–ç»„ä»¶
        self.perception_system = self._init_perception()
        self.reasoning_engine = self._init_reasoning()
        self.planning_system = self._init_planning()
        self.execution_system = self._init_execution()
        self.memory_system = self._init_memory()

    @abstractmethod
    def _init_perception(self):
        """åˆå§‹åŒ–æ„ŸçŸ¥ç³»ç»Ÿ"""
        pass

    @abstractmethod
    def _init_reasoning(self):
        """åˆå§‹åŒ–æ¨ç†å¼•æ“"""
        pass

    @abstractmethod
    def _init_planning(self):
        """åˆå§‹åŒ–è§„åˆ’ç³»ç»Ÿ"""
        pass

    @abstractmethod
    def _init_execution(self):
        """åˆå§‹åŒ–æ‰§è¡Œç³»ç»Ÿ"""
        pass

    @abstractmethod
    def _init_memory(self):
        """åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ"""
        pass

    async def perceive(self, environment_data: Dict[str, Any]) -> List[AgentPerception]:
        """æ„ŸçŸ¥ç¯å¢ƒ"""
        self.state = AgentState.OBSERVING

        perceptions = await self.perception_system.process(environment_data)
        self.perception_buffer.extend(perceptions)

        # ä¿æŒç¼“å†²åŒºå¤§å°
        if len(self.perception_buffer) > 100:
            self.perception_buffer = self.perception_buffer[-100:]

        self.state = AgentState.IDLE
        return perceptions

    async def reason(self, perceptions: List[AgentPerception]) -> Dict[str, Any]:
        """æ¨ç†å’Œå†³ç­–"""
        self.state = AgentState.THINKING

        reasoning_result = await self.reasoning_engine.reason(
            perceptions,
            self.current_goal,
            self.memory_system
        )

        self.state = AgentState.IDLE
        return reasoning_result

    async def plan(self, reasoning_result: Dict[str, Any]) -> List[AgentAction]:
        """åˆ¶å®šè®¡åˆ’"""
        self.state = AgentState.PLANNING

        plan = await self.planning_system.create_plan(
            reasoning_result,
            self.current_goal,
            self.action_history
        )

        self.state = AgentState.IDLE
        return plan

    async def execute(self, actions: List[AgentAction]) -> List[Dict[str, Any]]:
        """æ‰§è¡ŒåŠ¨ä½œ"""
        self.state = AgentState.ACTING

        results = []
        for action in actions:
            try:
                result = await self.execution_system.execute(action)
                self.action_history.append(action)
                results.append(result)
            except Exception as e:
                results.append({
                    'action': action,
                    'success': False,
                    'error': str(e)
                })

        self.state = AgentState.IDLE
        return results

    async def perceive_reason_plan_act(self, environment_data: Dict[str, Any]) -> Dict[str, Any]:
        """å®Œæ•´çš„æ„ŸçŸ¥-æ¨ç†-è§„åˆ’-æ‰§è¡Œå¾ªç¯"""
        start_time = time.time()

        try:
            # 1. æ„ŸçŸ¥
            perceptions = await self.perceive(environment_data)

            # 2. æ¨ç†
            reasoning_result = await self.reason(perceptions)

            # 3. è§„åˆ’
            actions = await self.plan(reasoning_result)

            # 4. æ‰§è¡Œ
            results = await self.execute(actions)

            execution_time = time.time() - start_time

            return {
                'success': True,
                'perceptions': perceptions,
                'reasoning_result': reasoning_result,
                'actions': actions,
                'results': results,
                'execution_time': execution_time
            }

        except Exception as e:
            self.state = AgentState.ERROR
            return {
                'success': False,
                'error': str(e),
                'execution_time': time.time() - start_time
            }

    def set_goal(self, goal: Dict[str, Any]):
        """è®¾ç½®ç›®æ ‡"""
        self.goal_stack.append(goal)
        self.current_goal = goal

    def complete_goal(self):
        """å®Œæˆå½“å‰ç›®æ ‡"""
        if self.goal_stack:
            self.goal_stack.pop()
            self.current_goal = self.goal_stack[-1] if self.goal_stack else None
```

## ğŸ§  æ„ŸçŸ¥ç³»ç»Ÿ

### å¤šæ¨¡æ€æ„ŸçŸ¥ç³»ç»Ÿ
```python
class MultiModalPerceptionSystem:
    """å¤šæ¨¡æ€æ„ŸçŸ¥ç³»ç»Ÿ"""

    def __init__(self):
        self.sensors = {}
        self.perception_fusion = PerceptionFusion()

    def register_sensor(self, sensor_name: str, sensor):
        """æ³¨å†Œä¼ æ„Ÿå™¨"""
        self.sensors[sensor_name] = sensor

    async def process(self, environment_data: Dict[str, Any]) -> List[AgentPerception]:
        """å¤„ç†ç¯å¢ƒæ•°æ®"""
        perceptions = []

        # å¤„ç†å„æ¨¡æ€æ•°æ®
        for sensor_name, sensor in self.sensors.items():
            if sensor_name in environment_data:
                sensor_data = environment_data[sensor_name]
                modal_perceptions = await sensor.process(sensor_data)
                perceptions.extend(modal_perceptions)

        # èåˆå¤šæ¨¡æ€æ„ŸçŸ¥
        if len(perceptions) > 1:
            fused_perception = await self.perception_fusion.fuse(perceptions)
            perceptions.append(fused_perception)

        return perceptions

class TextPerception:
    """æ–‡æœ¬æ„ŸçŸ¥"""

    async def process(self, text_data: str) -> List[AgentPerception]:
        perceptions = []

        # æ–‡æœ¬åˆ†æ
        from transformers import pipeline

        # æƒ…æ„Ÿåˆ†æ
        sentiment_analyzer = pipeline("sentiment-analysis")
        sentiment = sentiment_analyzer(text_data)[0]

        # å®ä½“è¯†åˆ«
        ner_analyzer = pipeline("ner", aggregation_strategy="simple")
        entities = ner_analyzer(text_data)

        # æ„å›¾è¯†åˆ«
        intent = await self._identify_intent(text_data)

        perception = AgentPerception(
            timestamp=time.time(),
            observations={
                'text': text_data,
                'sentiment': sentiment,
                'entities': entities,
                'intent': intent
            },
            confidence=0.8,
            source='text'
        )

        perceptions.append(perception)
        return perceptions

    async def _identify_intent(self, text: str) -> str:
        """è¯†åˆ«ç”¨æˆ·æ„å›¾"""
        # ç®€åŒ–çš„æ„å›¾è¯†åˆ«
        text_lower = text.lower()

        intents = {
            'question': ['ä»€ä¹ˆ', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', '?'],
            'request': ['è¯·', 'å¸®', 'éœ€è¦', 'æƒ³è¦'],
            'greeting': ['ä½ å¥½', 'hello', 'hi'],
            'goodbye': ['å†è§', 'bye', 'æ‹œæ‹œ']
        }

        for intent, keywords in intents.items():
            if any(keyword in text_lower for keyword in keywords):
                return intent

        return 'general'

class ImagePerception:
    """å›¾åƒæ„ŸçŸ¥"""

    def __init__(self):
        from transformers import BlipProcessor, BlipForConditionalGeneration
        from PIL import Image

        self.processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
        self.model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

    async def process(self, image_data) -> List[AgentPerception]:
        perceptions = []

        # å›¾åƒæè¿°ç”Ÿæˆ
        inputs = self.processor(image_data, return_tensors="pt")
        out = self.model.generate(**inputs, max_length=50)
        description = self.processor.decode(out[0], skip_special_tokens=True)

        # ç‰©ä½“æ£€æµ‹
        objects = await self._detect_objects(image_data)

        # åœºæ™¯åˆ†æ
        scene = await self._analyze_scene(image_data)

        perception = AgentPerception(
            timestamp=time.time(),
            observations={
                'description': description,
                'objects': objects,
                'scene': scene
            },
            confidence=0.7,
            source='image'
        )

        perceptions.append(perception)
        return perceptions

    async def _detect_objects(self, image_data) -> List[str]:
        """æ£€æµ‹ç‰©ä½“"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨ä¸“é—¨çš„ç‰©ä½“æ£€æµ‹æ¨¡å‹
        return ['person', 'car', 'building']

    async def _analyze_scene(self, image_data) -> str:
        """åˆ†æåœºæ™¯"""
        # ç®€åŒ–å®ç°
        return 'outdoor urban scene'

class PerceptionFusion:
    """æ„ŸçŸ¥èåˆ"""

    async def fuse(self, perceptions: List[AgentPerception]) -> AgentPerception:
        """èåˆå¤šæ¨¡æ€æ„ŸçŸ¥ä¿¡æ¯"""
        # åˆå¹¶è§‚å¯Ÿæ•°æ®
        merged_observations = {}
        total_confidence = 0
        sources = []

        for perception in perceptions:
            merged_observations.update(perception.observations)
            total_confidence += perception.confidence
            sources.append(perception.source)

        # è®¡ç®—èåˆåçš„ç½®ä¿¡åº¦
        avg_confidence = total_confidence / len(perceptions)

        # æ·»åŠ èåˆä¿¡æ¯
        merged_observations['fusion_info'] = {
            'fused_sources': sources,
            'fusion_method': 'weighted_average',
            'fusion_timestamp': time.time()
        }

        fused_perception = AgentPerception(
            timestamp=time.time(),
            observations=merged_observations,
            confidence=avg_confidence,
            source='fusion'
        )

        return fused_perception
```

## ğŸ§­ æ¨ç†å¼•æ“

### åŸºäºè§„åˆ™çš„æ¨ç†ç³»ç»Ÿ
```python
class RuleBasedReasoningEngine:
    """åŸºäºè§„åˆ™çš„æ¨ç†å¼•æ“"""

    def __init__(self):
        self.rules = []
        self.inference_engine = SimpleInferenceEngine()

    def add_rule(self, condition, conclusion, confidence=1.0):
        """æ·»åŠ æ¨ç†è§„åˆ™"""
        rule = {
            'condition': condition,
            'conclusion': conclusion,
            'confidence': confidence
        }
        self.rules.append(rule)

    async def reason(self, perceptions: List[AgentPerception],
                    current_goal: Optional[Dict],
                    memory_system) -> Dict[str, Any]:
        """æ‰§è¡Œæ¨ç†"""
        facts = self._extract_facts(perceptions)

        # åº”ç”¨è§„åˆ™è¿›è¡Œæ¨ç†
        conclusions = []
        for rule in self.rules:
            if self._match_condition(rule['condition'], facts):
                conclusions.append({
                    'conclusion': rule['conclusion'],
                    'confidence': rule['confidence'],
                    'rule_applied': rule
                })

        # é€‰æ‹©æœ€é«˜ç½®ä¿¡åº¦çš„ç»“è®º
        if conclusions:
            best_conclusion = max(conclusions, key=lambda x: x['confidence'])

            return {
                'reasoning_type': 'rule_based',
                'conclusion': best_conclusion['conclusion'],
                'confidence': best_conclusion['confidence'],
                'applied_rules': [best_conclusion['rule_applied']],
                'facts_used': facts
            }
        else:
            return {
                'reasoning_type': 'rule_based',
                'conclusion': None,
                'confidence': 0.0,
                'applied_rules': [],
                'facts_used': facts
            }

    def _extract_facts(self, perceptions: List[AgentPerception]) -> Dict[str, Any]:
        """ä»æ„ŸçŸ¥ä¸­æå–äº‹å®"""
        facts = {}

        for perception in perceptions:
            facts.update(perception.observations)

        return facts

    def _match_condition(self, condition: str, facts: Dict[str, Any]) -> bool:
        """åŒ¹é…è§„åˆ™æ¡ä»¶"""
        # ç®€åŒ–çš„æ¡ä»¶åŒ¹é…ï¼Œå®é™…åº”è¯¥ä½¿ç”¨æ›´å¤æ‚çš„é€»è¾‘
        try:
            # å®‰å…¨çš„å­—å…¸è®¿é—®
            for key, value in condition.items():
                if key not in facts or facts[key] != value:
                    return False
            return True
        except:
            return False

class NeuralReasoningEngine:
    """åŸºäºç¥ç»ç½‘ç»œçš„æ¨ç†å¼•æ“"""

    def __init__(self):
        self.model = self._build_reasoning_model()
        self.reasoning_history = []

    def _build_reasoning_model(self):
        """æ„å»ºæ¨ç†æ¨¡å‹"""
        import torch
        import torch.nn as nn

        class ReasoningNetwork(nn.Module):
            def __init__(self, input_dim, hidden_dim, output_dim):
                super().__init__()
                self.fc1 = nn.Linear(input_dim, hidden_dim)
                self.fc2 = nn.Linear(hidden_dim, hidden_dim)
                self.fc3 = nn.Linear(hidden_dim, output_dim)
                self.dropout = nn.Dropout(0.1)

            def forward(self, x):
                x = torch.relu(self.fc1(x))
                x = self.dropout(x)
                x = torch.relu(self.fc2(x))
                x = self.dropout(x)
                x = torch.softmax(self.fc3(x), dim=-1)
                return x

        return ReasoningNetwork(512, 256, 128)

    async def reason(self, perceptions: List[AgentPerception],
                    current_goal: Optional[Dict],
                    memory_system) -> Dict[str, Any]:
        """ç¥ç»ç½‘ç»œæ¨ç†"""
        # ç‰¹å¾æå–
        features = self._extract_features(perceptions, current_goal, memory_system)

        # ç¥ç»ç½‘ç»œæ¨ç†
        import torch
        with torch.no_grad():
            reasoning_output = self.model(features)

        # è§£ææ¨ç†ç»“æœ
        reasoning_result = self._parse_neural_output(reasoning_output)

        self.reasoning_history.append({
            'timestamp': time.time(),
            'input_features': features,
            'output': reasoning_result
        })

        return reasoning_result

    def _extract_features(self, perceptions, current_goal, memory_system):
        """æå–æ¨ç†ç‰¹å¾"""
        # ç®€åŒ–çš„ç‰¹å¾æå–
        import numpy as np

        # æ„ŸçŸ¥ç‰¹å¾
        perception_features = []
        for perception in perceptions:
            perception_features.extend([
                perception.confidence,
                len(str(perception.observations))
            ])

        # ç›®æ ‡ç‰¹å¾
        goal_features = [0] * 50  # ç®€åŒ–å¤„ç†
        if current_goal:
            goal_features = [
                len(str(current_goal)),
                current_goal.get('priority', 0) / 10.0,
                current_goal.get('urgency', 0) / 10.0
            ] + [0] * 47

        # è®°å¿†ç‰¹å¾
        memory_features = [0] * 256  # ç®€åŒ–å¤„ç†

        # åˆå¹¶ç‰¹å¾
        features = perception_features[:10] + goal_features[:50] + memory_features[:200]

        # å¡«å……åˆ°å›ºå®šé•¿åº¦
        while len(features) < 512:
            features.append(0)

        import torch
        return torch.FloatTensor(features)

    def _parse_neural_output(self, output):
        """è§£æç¥ç»ç½‘ç»œè¾“å‡º"""
        import torch

        # è·å–æœ€å¯èƒ½çš„æ¨ç†ç»“æœ
        probabilities = torch.softmax(output, dim=-1)
        max_prob, max_index = torch.max(probabilities, dim=-1)

        reasoning_types = [
            'action_selection', 'goal_planning', 'problem_solving',
            'decision_making', 'learning', 'communication'
        ]

        return {
            'reasoning_type': 'neural',
            'conclusion': reasoning_types[max_index] if max_index < len(reasoning_types) else 'unknown',
            'confidence': max_prob.item(),
            'probabilities': probabilities.tolist(),
            'all_probabilities': {
                reasoning_types[i]: prob for i, prob in enumerate(probabilities.tolist())
                if i < len(reasoning_types)
            }
        }
```

## ğŸ“‹ è§„åˆ’ç³»ç»Ÿ

### å±‚æ¬¡åŒ–ä»»åŠ¡è§„åˆ’
```python
class HierarchicalPlanner:
    """å±‚æ¬¡åŒ–ä»»åŠ¡è§„åˆ’å™¨"""

    def __init__(self):
        self.task_library = TaskLibrary()
        self.plan_optimizer = PlanOptimizer()

    async def create_plan(self, reasoning_result: Dict[str, Any],
                         current_goal: Optional[Dict],
                         action_history: List) -> List[AgentAction]:
        """åˆ›å»ºæ‰§è¡Œè®¡åˆ’"""
        if not current_goal:
            return []

        # åˆ†è§£ç›®æ ‡ä¸ºå­ä»»åŠ¡
        subtasks = await self._decompose_goal(current_goal)

        # ä¸ºæ¯ä¸ªå­ä»»åŠ¡é€‰æ‹©åŠ¨ä½œ
        actions = []
        for subtask in subtasks:
            task_actions = await self._plan_subtask(subtask)
            actions.extend(task_actions)

        # ä¼˜åŒ–è®¡åˆ’
        optimized_actions = await self.plan_optimizer.optimize(actions)

        return optimized_actions

    async def _decompose_goal(self, goal: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åˆ†è§£ç›®æ ‡ä¸ºå­ä»»åŠ¡"""
        goal_type = goal.get('type', 'general')

        if goal_type == 'conversation':
            return await self._decompose_conversation_goal(goal)
        elif goal_type == 'information_retrieval':
            return await self._decompose_retrieval_goal(goal)
        elif goal_type == 'problem_solving':
            return await self._decompose_problem_goal(goal)
        else:
            return [goal]  # ä¸åˆ†è§£

    async def _decompose_conversation_goal(self, goal: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åˆ†è§£å¯¹è¯ç›®æ ‡"""
        subtasks = []

        # ç†è§£ç”¨æˆ·æ„å›¾
        subtasks.append({
            'type': 'intent_understanding',
            'input': goal.get('user_input', ''),
            'priority': 1
        })

        # æ£€ç´¢ç›¸å…³ä¿¡æ¯
        subtasks.append({
            'type': 'information_retrieval',
            'query': goal.get('user_input', ''),
            'priority': 2
        })

        # ç”Ÿæˆå“åº”
        subtasks.append({
            'type': 'response_generation',
            'context': goal.get('context', {}),
            'priority': 3
        })

        return subtasks

    async def _plan_subtask(self, subtask: Dict[str, Any]) -> List[AgentAction]:
        """ä¸ºå­ä»»åŠ¡è§„åˆ’åŠ¨ä½œ"""
        task_type = subtask['type']

        if task_type == 'intent_understanding':
            return [
                AgentAction(
                    action_type='analyze_intent',
                    parameters={'text': subtask['input']},
                    confidence=0.9,
                    expected_outcome='intent_classified'
                )
            ]
        elif task_type == 'information_retrieval':
            return [
                AgentAction(
                    action_type='search_knowledge',
                    parameters={'query': subtask['query']},
                    confidence=0.8,
                    expected_outcome='relevant_documents_found'
                )
            ]
        elif task_type == 'response_generation':
            return [
                AgentAction(
                    action_type='generate_response',
                    parameters={'context': subtask['context']},
                    confidence=0.8,
                    expected_outcome='response_generated'
                )
            ]

        return []

    async def optimize_plan(self, actions: List[AgentAction]) -> List[AgentAction]:
        """ä¼˜åŒ–æ‰§è¡Œè®¡åˆ’"""
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        sorted_actions = sorted(actions, key=lambda x: self._get_action_priority(x))

        # ç§»é™¤å†—ä½™åŠ¨ä½œ
        optimized_actions = self._remove_redundant_actions(sorted_actions)

        # åˆå¹¶ç›¸ä¼¼åŠ¨ä½œ
        merged_actions = self._merge_similar_actions(optimized_actions)

        return merged_actions

    def _get_action_priority(self, action: AgentAction) -> int:
        """è·å–åŠ¨ä½œä¼˜å…ˆçº§"""
        priorities = {
            'analyze_intent': 1,
            'search_knowledge': 2,
            'generate_response': 3,
            'execute_tool': 2,
            'update_memory': 4
        }

        return priorities.get(action.action_type, 5)

    def _remove_redundant_actions(self, actions: List[AgentAction]) -> List[AgentAction]:
        """ç§»é™¤å†—ä½™åŠ¨ä½œ"""
        unique_actions = []
        seen_action_types = set()

        for action in actions:
            if action.action_type not in seen_action_types:
                unique_actions.append(action)
                seen_action_types.add(action.action_type)

        return unique_actions

    def _merge_similar_actions(self, actions: List[AgentAction]) -> List[AgentAction]:
        """åˆå¹¶ç›¸ä¼¼åŠ¨ä½œ"""
        # ç®€åŒ–å®ç°ï¼šæŒ‰åŠ¨ä½œç±»å‹åˆ†ç»„
        action_groups = {}
        for action in actions:
            action_type = action.action_type
            if action_type not in action_groups:
                action_groups[action_type] = []
            action_groups[action_type].append(action)

        # åˆå¹¶åŒç±»å‹åŠ¨ä½œ
        merged_actions = []
        for action_type, group_actions in action_groups.items():
            if len(group_actions) == 1:
                merged_actions.extend(group_actions)
            else:
                # åˆå¹¶å‚æ•°
                merged_params = {}
                for action in group_actions:
                    merged_params.update(action.parameters)

                merged_action = AgentAction(
                    action_type=action_type,
                    parameters=merged_params,
                    confidence=sum(a.confidence for a in group_actions) / len(group_actions),
                    expected_outcome=f"merged_{action_type}_result"
                )
                merged_actions.append(merged_action)

        return merged_actions

class TaskLibrary:
    """ä»»åŠ¡åº“"""

    def __init__(self):
        self.tasks = {
            'conversation': {
                'subtasks': ['understand_intent', 'retrieve_context', 'generate_response'],
                'success_criteria': ['intent_understood', 'context_retrieved', 'response_relevant']
            },
            'search': {
                'subtasks': ['parse_query', 'execute_search', 'rank_results'],
                'success_criteria': ['query_parsed', 'search_executed', 'results_ranked']
            }
        }

    def get_task_template(self, task_type: str) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡æ¨¡æ¿"""
        return self.tasks.get(task_type, {})

class PlanOptimizer:
    """è®¡åˆ’ä¼˜åŒ–å™¨"""

    async def optimize(self, actions: List[AgentAction]) -> List[AgentAction]:
        """ä¼˜åŒ–åŠ¨ä½œåºåˆ—"""
        # æ—¶é—´å¤æ‚åº¦ä¼˜åŒ–
        optimized = self._optimize_time_complexity(actions)

        # èµ„æºä½¿ç”¨ä¼˜åŒ–
        optimized = self._optimize_resource_usage(optimized)

        # å¹¶è¡ŒåŒ–ä¼˜åŒ–
        optimized = self._enable_parallel_execution(optimized)

        return optimized

    def _optimize_time_complexity(self, actions: List[AgentAction]) -> List[AgentAction]:
        """ä¼˜åŒ–æ—¶é—´å¤æ‚åº¦"""
        # å°†ç‹¬ç«‹åŠ¨ä½œç§»åˆ°å‰é¢æ‰§è¡Œ
        independent_actions = []
        dependent_actions = []

        for action in actions:
            if self._is_independent(action, actions):
                independent_actions.append(action)
            else:
                dependent_actions.append(action)

        return independent_actions + dependent_actions

    def _is_independent(self, action: AgentAction, all_actions: List[AgentAction]) -> bool:
        """æ£€æŸ¥åŠ¨ä½œæ˜¯å¦ç‹¬ç«‹"""
        # ç®€åŒ–å®ç°
        independent_actions = ['update_memory', 'log_activity']
        return action.action_type in independent_actions

    def _optimize_resource_usage(self, actions: List[AgentAction]) -> List[AgentAction]:
        """ä¼˜åŒ–èµ„æºä½¿ç”¨"""
        # å°†èµ„æºå¯†é›†å‹åŠ¨ä½œåˆ†æ•£æ‰§è¡Œ
        cpu_intensive = []
        memory_intensive = []
        normal = []

        for action in actions:
            if self._is_cpu_intensive(action):
                cpu_intensive.append(action)
            elif self._is_memory_intensive(action):
                memory_intensive.append(action)
            else:
                normal.append(action)

        # äº¤é”™æ‰§è¡Œ
        optimized = []
        max_length = max(len(cpu_intensive), len(memory_intensive), len(normal))

        for i in range(max_length):
            if i < len(normal):
                optimized.append(normal[i])
            if i < len(memory_intensive):
                optimized.append(memory_intensive[i])
            if i < len(cpu_intensive):
                optimized.append(cpu_intensive[i])

        return optimized

    def _enable_parallel_execution(self, actions: List[AgentAction]) -> List[AgentAction]:
        """å¯ç”¨å¹¶è¡Œæ‰§è¡Œ"""
        # æ ‡è®°å¯å¹¶è¡Œæ‰§è¡Œçš„åŠ¨ä½œ
        for action in actions:
            if self._can_run_parallel(action):
                action.parameters['parallel'] = True

        return actions

    def _is_cpu_intensive(self, action: AgentAction) -> bool:
        """æ£€æŸ¥æ˜¯å¦CPUå¯†é›†"""
        cpu_intensive_actions = ['generate_response', 'search_knowledge']
        return action.action_type in cpu_intensive_actions

    def _is_memory_intensive(self, action: AgentAction) -> bool:
        """æ£€æŸ¥æ˜¯å¦å†…å­˜å¯†é›†"""
        memory_intensive_actions = ['load_model', 'process_large_data']
        return action.action_type in memory_intensive_actions

    def _can_run_parallel(self, action: AgentAction) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯å¹¶è¡Œæ‰§è¡Œ"""
        parallel_actions = ['search_knowledge', 'update_memory', 'log_activity']
        return action.action_type in parallel_actions
```

## âš™ï¸ æ‰§è¡Œç³»ç»Ÿ

### å¤šçº¿ç¨‹æ‰§è¡Œå¼•æ“
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor, as_completed

class ExecutionEngine:
    """æ‰§è¡Œå¼•æ“"""

    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
        self.tool_registry = ToolRegistry()
        self.execution_history = []

    async def execute(self, actions: List[AgentAction]) -> List[Dict[str, Any]]:
        """æ‰§è¡ŒåŠ¨ä½œåˆ—è¡¨"""
        results = []

        # åˆ†æåŠ¨ä½œä¾èµ–å…³ç³»
        dependency_graph = self._build_dependency_graph(actions)

        # æ‰§è¡ŒåŠ¨ä½œ
        if self._has_dependencies(dependency_graph):
            # æœ‰ä¾èµ–å…³ç³»ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œ
            results = await self._execute_with_dependencies(actions, dependency_graph)
        else:
            # æ— ä¾èµ–å…³ç³»ï¼Œå¹¶è¡Œæ‰§è¡Œ
            results = await self._execute_parallel(actions)

        # è®°å½•æ‰§è¡Œå†å²
        self.execution_history.append({
            'timestamp': time.time(),
            'actions': actions,
            'results': results
        })

        return results

    async def _execute_parallel(self, actions: List[AgentAction]) -> List[Dict[str, Any]]:
        """å¹¶è¡Œæ‰§è¡ŒåŠ¨ä½œ"""
        results = []

        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
        tasks = []
        for action in actions:
            if action.parameters.get('parallel', False):
                task = self._execute_single_action(action)
                tasks.append(task)
            else:
                # ä¸²è¡Œæ‰§è¡Œ
                result = await self._execute_single_action(action)
                results.append(result)

        # å¹¶è¡Œæ‰§è¡Œ
        if tasks:
            parallel_results = await asyncio.gather(*tasks)
            results.extend(parallel_results)

        return results

    async def _execute_with_dependencies(self, actions: List[AgentAction],
                                       dependency_graph: Dict) -> List[Dict[str, Any]]:
        """æŒ‰ä¾èµ–å…³ç³»æ‰§è¡Œ"""
        results = []
        executed = set()

        while len(executed) < len(actions):
            # æ‰¾åˆ°å¯ä»¥æ‰§è¡Œçš„åŠ¨ä½œ
            ready_actions = []
            for i, action in enumerate(actions):
                if i not in executed:
                    dependencies = dependency_graph.get(i, [])
                    if all(dep in executed for dep in dependencies):
                        ready_actions.append((i, action))

            # æ‰§è¡Œå°±ç»ªçš„åŠ¨ä½œ
            for idx, action in ready_actions:
                result = await self._execute_single_action(action)
                results.append(result)
                executed.add(idx)

        return results

    async def _execute_single_action(self, action: AgentAction) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªåŠ¨ä½œ"""
        start_time = time.time()

        try:
            # è·å–å·¥å…·
            tool = self.tool_registry.get_tool(action.action_type)

            if tool is None:
                raise ValueError(f"Unknown action type: {action.action_type}")

            # æ‰§è¡Œå·¥å…·
            result = await tool.execute(action.parameters)

            execution_time = time.time() - start_time

            return {
                'action': action,
                'success': True,
                'result': result,
                'execution_time': execution_time
            }

        except Exception as e:
            execution_time = time.time() - start_time

            return {
                'action': action,
                'success': False,
                'error': str(e),
                'execution_time': execution_time
            }

    def _build_dependency_graph(self, actions: List[AgentAction]) -> Dict[int, List[int]]:
        """æ„å»ºä¾èµ–å…³ç³»å›¾"""
        # ç®€åŒ–çš„ä¾èµ–å…³ç³»æ„å»º
        dependencies = {}

        for i, action in enumerate(actions):
            deps = []

            # æœç´¢åŠ¨ä½œä¾èµ–äºç†è§£æ„å›¾
            if action.action_type == 'search_knowledge':
                for j, prev_action in enumerate(actions[:i]):
                    if prev_action.action_type == 'analyze_intent':
                        deps.append(j)

            # å“åº”ç”Ÿæˆä¾èµ–äºæœç´¢å’Œæ„å›¾ç†è§£
            elif action.action_type == 'generate_response':
                for j, prev_action in enumerate(actions[:i]):
                    if prev_action.action_type in ['analyze_intent', 'search_knowledge']:
                        deps.append(j)

            dependencies[i] = deps

        return dependencies

    def _has_dependencies(self, dependency_graph: Dict[int, List[int]]) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰ä¾èµ–å…³ç³»"""
        return any(deps for deps in dependency_graph.values())

class ToolRegistry:
    """å·¥å…·æ³¨å†Œå™¨"""

    def __init__(self):
        self.tools = {}

    def register_tool(self, name: str, tool):
        """æ³¨å†Œå·¥å…·"""
        self.tools[name] = tool

    def get_tool(self, name: str):
        """è·å–å·¥å…·"""
        return self.tools.get(name)

# ç¤ºä¾‹å·¥å…·å®ç°
class SearchTool:
    """æœç´¢å·¥å…·"""

    async def execute(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæœç´¢"""
        query = parameters.get('query', '')

        # æ¨¡æ‹Ÿæœç´¢
        await asyncio.sleep(0.5)

        results = [
            {'title': f"Search result for: {query}",
             'content': f"Content about {query}",
             'relevance': 0.9}
        ]

        return {
            'results': results,
            'query': query,
            'count': len(results)
        }

class GenerateResponseTool:
    """å“åº”ç”Ÿæˆå·¥å…·"""

    async def execute(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå“åº”"""
        context = parameters.get('context', {})

        # æ¨¡æ‹Ÿç”Ÿæˆ
        await asyncio.sleep(0.3)

        response = f"Generated response based on context: {str(context)[:50]}..."

        return {
            'response': response,
            'tokens': len(response.split()),
            'confidence': 0.8
        }
```

## ğŸ’¾ è®°å¿†ç³»ç»Ÿ

### åˆ†å±‚è®°å¿†æ¶æ„
```python
class LayeredMemorySystem:
    """åˆ†å±‚è®°å¿†ç³»ç»Ÿ"""

    def __init__(self):
        self.working_memory = WorkingMemory(capacity=7)
        self.episodic_memory = EpisodicMemory()
        self.semantic_memory = SemanticMemory()
        self.procedural_memory = ProceduralMemory()

    async def store(self, information: Dict[str, Any], memory_type: str = 'auto') -> str:
        """å­˜å‚¨ä¿¡æ¯åˆ°è®°å¿†ç³»ç»Ÿ"""
        if memory_type == 'auto':
            memory_type = self._determine_memory_type(information)

        if memory_type == 'working':
            return await self.working_memory.store(information)
        elif memory_type == 'episodic':
            return await self.episodic_memory.store(information)
        elif memory_type == 'semantic':
            return await self.semantic_memory.store(information)
        elif memory_type == 'procedural':
            return await self.procedural_memory.store(information)

        return None

    async def retrieve(self, query: Dict[str, Any], memory_type: str = 'all') -> List[Dict[str, Any]]:
        """ä»è®°å¿†ç³»ç»Ÿæ£€ç´¢ä¿¡æ¯"""
        results = []

        if memory_type in ['all', 'working']:
            results.extend(await self.working_memory.retrieve(query))
        if memory_type in ['all', 'episodic']:
            results.extend(await self.episodic_memory.retrieve(query))
        if memory_type in ['all', 'semantic']:
            results.extend(await self.semantic_memory.retrieve(query))
        if memory_type in ['all', 'procedural']:
            results.extend(await self.procedural_memory.retrieve(query))

        return results

    def _determine_memory_type(self, information: Dict[str, Any]) -> str:
        """è‡ªåŠ¨ç¡®å®šè®°å¿†ç±»å‹"""
        # ç®€åŒ–çš„è®°å¿†ç±»å‹åˆ¤æ–­
        if 'action' in information:
            return 'procedural'
        elif 'conversation' in information:
            return 'episodic'
        elif 'fact' in information:
            return 'semantic'
        else:
            return 'working'

class WorkingMemory:
    """å·¥ä½œè®°å¿†"""

    def __init__(self, capacity: int = 7):
        self.capacity = capacity
        self.items = []
        self.access_count = {}

    async def store(self, information: Dict[str, Any]) -> str:
        """å­˜å‚¨åˆ°å·¥ä½œè®°å¿†"""
        import uuid

        item_id = str(uuid.uuid4())
        item = {
            'id': item_id,
            'information': information,
            'timestamp': time.time()
        }

        self.items.append(item)
        self.access_count[item_id] = 1

        # ç»´æŠ¤å®¹é‡é™åˆ¶
        if len(self.items) > self.capacity:
            # ç§»é™¤è®¿é—®æ¬¡æ•°æœ€å°‘çš„é¡¹
            oldest_item = min(self.items,
                           key=lambda x: self.access_count.get(x['id'], 0))
            self.items.remove(oldest_item)
            del self.access_count[oldest_item['id']]

        return item_id

    async def retrieve(self, query: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä»å·¥ä½œè®°å¿†æ£€ç´¢"""
        results = []

        for item in self.items:
            if self._match_query(item['information'], query):
                self.access_count[item['id']] = self.access_count.get(item['id'], 0) + 1
                results.append(item)

        return results

    def _match_query(self, information: Dict[str, Any], query: Dict[str, Any]) -> bool:
        """åŒ¹é…æŸ¥è¯¢"""
        # ç®€åŒ–çš„åŒ¹é…é€»è¾‘
        for key, value in query.items():
            if key in information and information[key] != value:
                return False
        return True

class EpisodicMemory:
    """æƒ…æ™¯è®°å¿†"""

    def __init__(self):
        self.episodes = []
        self.episode_index = {}

    async def store(self, information: Dict[str, Any]) -> str:
        """å­˜å‚¨æƒ…æ™¯è®°å¿†"""
        import uuid

        episode_id = str(uuid.uuid4())
        episode = {
            'id': episode_id,
            'information': information,
            'timestamp': time.time(),
            'emotional_weight': self._calculate_emotional_weight(information)
        }

        self.episodes.append(episode)
        self._update_index(episode)

        return episode_id

    async def retrieve(self, query: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ£€ç´¢æƒ…æ™¯è®°å¿†"""
        results = []

        # ç®€åŒ–çš„æ£€ç´¢é€»è¾‘
        for episode in self.episodes:
            if self._match_query(episode['information'], query):
                results.append(episode)

        # æŒ‰æ—¶é—´å€’åºæ’åˆ—
        results.sort(key=lambda x: x['timestamp'], reverse=True)

        return results[:10]  # è¿”å›æœ€è¿‘10ä¸ªç›¸å…³æƒ…æ™¯

    def _calculate_emotional_weight(self, information: Dict[str, Any]) -> float:
        """è®¡ç®—æƒ…æ„Ÿæƒé‡"""
        # ç®€åŒ–å®ç°
        return information.get('importance', 0.5)

    def _update_index(self, episode: Dict[str, Any]):
        """æ›´æ–°ç´¢å¼•"""
        # ç®€åŒ–å®ç°ï¼šæŒ‰å…³é”®è¯ç´¢å¼•
        keywords = self._extract_keywords(episode['information'])

        for keyword in keywords:
            if keyword not in self.episode_index:
                self.episode_index[keyword] = []
            self.episode_index[keyword].append(episode['id'])

    def _extract_keywords(self, information: Dict[str, Any]) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€åŒ–å®ç°
        text = str(information)
        return text.lower().split()[:5]  # å–å‰5ä¸ªè¯ä½œä¸ºå…³é”®è¯

    def _match_query(self, information: Dict[str, Any], query: Dict[str, Any]) -> bool:
        """åŒ¹é…æŸ¥è¯¢"""
        # ç®€åŒ–çš„åŒ¹é…é€»è¾‘
        query_text = str(query).lower()
        info_text = str(information).lower()
        return query_text in info_text

class SemanticMemory:
    """è¯­ä¹‰è®°å¿†"""

    def __init__(self):
        self.facts = {}
        self.concepts = {}

    async def store(self, information: Dict[str, Any]) -> str:
        """å­˜å‚¨è¯­ä¹‰è®°å¿†"""
        import uuid

        fact_id = str(uuid.uuid4())

        fact = {
            'id': fact_id,
            'fact': information,
            'timestamp': time.time(),
            'confidence': information.get('confidence', 1.0)
        }

        self.facts[fact_id] = fact

        # æ›´æ–°æ¦‚å¿µç½‘ç»œ
        self._update_concept_network(fact)

        return fact_id

    async def retrieve(self, query: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ£€ç´¢è¯­ä¹‰è®°å¿†"""
        results = []

        for fact in self.facts.values():
            if self._semantic_match(fact['fact'], query):
                results.append(fact)

        # æŒ‰ç½®ä¿¡åº¦æ’åº
        results.sort(key=lambda x: x['confidence'], reverse=True)

        return results

    def _semantic_match(self, fact: Dict[str, Any], query: Dict[str, Any]) -> bool:
        """è¯­ä¹‰åŒ¹é…"""
        # ç®€åŒ–å®ç°
        fact_text = str(fact).lower()
        query_text = str(query).lower()

        # æ£€æŸ¥å…³é”®è¯é‡å 
        fact_words = set(fact_text.split())
        query_words = set(query_text.split())

        overlap = fact_words & query_words
        return len(overlap) > 0

    def _update_concept_network(self, fact: Dict[str, Any]):
        """æ›´æ–°æ¦‚å¿µç½‘ç»œ"""
        # ç®€åŒ–å®ç°
        words = str(fact['fact']).split()

        for word in words:
            if word not in self.concepts:
                self.concepts[word] = []
            self.concepts[word].append(fact['id'])

class ProceduralMemory:
    """ç¨‹åºæ€§è®°å¿†"""

    def __init__(self):
        self.procedures = {}
        self.skills = {}

    async def store(self, information: Dict[str, Any]) -> str:
        """å­˜å‚¨ç¨‹åºæ€§è®°å¿†"""
        import uuid

        procedure_id = str(uuid.uuid4())

        procedure = {
            'id': procedure_id,
            'procedure': information,
            'timestamp': time.time(),
            'success_rate': 1.0,
            'usage_count': 0
        }

        self.procedures[procedure_id] = procedure
        self._update_skills(procedure)

        return procedure_id

    async def retrieve(self, query: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ£€ç´¢ç¨‹åºæ€§è®°å¿†"""
        results = []

        for procedure in self.procedures.values():
            if self._procedure_match(procedure['procedure'], query):
                results.append(procedure)

        # æŒ‰æˆåŠŸç‡æ’åº
        results.sort(key=lambda x: x['success_rate'], reverse=True)

        return results

    def _procedure_match(self, procedure: Dict[str, Any], query: Dict[str, Any]) -> bool:
        """åŒ¹é…ç¨‹åº"""
        # ç®€åŒ–å®ç°
        procedure_type = procedure.get('type', '')
        query_type = query.get('type', '')

        return procedure_type == query_type

    def _update_skills(self, procedure: Dict[str, Any]):
        """æ›´æ–°æŠ€èƒ½åº“"""
        skill_type = procedure['procedure'].get('type', 'general')

        if skill_type not in self.skills:
            self.skills[skill_type] = []

        self.skills[skill_type].append(procedure['id'])
```

## ğŸ“Š Agentæ¶æ„ç¤ºä¾‹

### å®Œæ•´çš„å¯¹è¯Agent
```python
class ConversationalAgent(BaseAgent):
    """å¯¹è¯Agent"""

    def _init_perception(self):
        """åˆå§‹åŒ–æ„ŸçŸ¥ç³»ç»Ÿ"""
        perception_system = MultiModalPerceptionSystem()

        # æ³¨å†Œæ–‡æœ¬æ„ŸçŸ¥
        perception_system.register_sensor('text', TextPerception())

        # æ³¨å†Œå›¾åƒæ„ŸçŸ¥
        perception_system.register_sensor('image', ImagePerception())

        return perception_system

    def _init_reasoning(self):
        """åˆå§‹åŒ–æ¨ç†å¼•æ“"""
        # æ··åˆæ¨ç†å¼•æ“
        self.rule_engine = RuleBasedReasoningEngine()
        self.neural_engine = NeuralReasoningEngine()

        # æ·»åŠ åŸºç¡€è§„åˆ™
        self.rule_engine.add_rule(
            condition={'conversation': True},
            conclusion={'type': 'conversation'},
            confidence=0.9
        )

        return self.rule_engine

    def _init_planning(self):
        """åˆå§‹åŒ–è§„åˆ’ç³»ç»Ÿ"""
        return HierarchicalPlanner()

    def _init_execution(self):
        """åˆå§‹åŒ–æ‰§è¡Œç³»ç»Ÿ"""
        execution_engine = ExecutionEngine(max_workers=4)

        # æ³¨å†Œå·¥å…·
        execution_engine.tool_registry.register_tool('analyze_intent', IntentAnalysisTool())
        execution_engine.tool_registry.register_tool('search_knowledge', SearchTool())
        execution_engine.tool_registry.register_tool('generate_response', GenerateResponseTool())
        execution_engine.tool_registry.register_tool('update_memory', MemoryUpdateTool())

        return execution_engine

    def _init_memory(self):
        """åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ"""
        return LayeredMemorySystem()

    async def handle_conversation(self, user_input: str, context: Dict[str, Any] = None) -> str:
        """å¤„ç†å¯¹è¯"""
        # è®¾ç½®ç›®æ ‡
        goal = {
            'type': 'conversation',
            'user_input': user_input,
            'context': context or {},
            'priority': 1.0
        }
        self.set_goal(goal)

        # æ‰§è¡Œæ„ŸçŸ¥-æ¨ç†-è§„åˆ’-æ‰§è¡Œå¾ªç¯
        environment_data = {
            'text': user_input,
            'context': context or {}
        }

        result = await self.perceive_reason_plan_act(environment_data)

        if result['success']:
            # æå–å“åº”
            for action_result in result['results']:
                if action_result['success']:
                    if action_result['action'].action_type == 'generate_response':
                        response = action_result['result']['response']

                        # å­˜å‚¨åˆ°è®°å¿†
                        await self.memory_system.store({
                            'type': 'conversation',
                            'user_input': user_input,
                            'agent_response': response,
                            'timestamp': time.time()
                        }, 'episodic')

                        return response

        return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚"

# ä½¿ç”¨ç¤ºä¾‹
async def test_conversational_agent():
    """æµ‹è¯•å¯¹è¯Agent"""
    agent = ConversationalAgent("chat_agent")

    # å¤„ç†å¯¹è¯
    response1 = await agent.handle_conversation("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
    print(f"ç”¨æˆ·: ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
    print(f"Agent: {response1}")

    response2 = await agent.handle_conversation("ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")
    print(f"ç”¨æˆ·: ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")
    print(f"Agent: {response2}")

    # å¤„ç†å¸¦ä¸Šä¸‹æ–‡çš„å¯¹è¯
    response3 = await agent.handle_conversation(
        "é‚£æ·±åº¦å­¦ä¹ å‘¢ï¼Ÿ",
        context={'previous_topic': 'artificial_intelligence'}
    )
    print(f"ç”¨æˆ·: é‚£æ·±åº¦å­¦ä¹ å‘¢ï¼Ÿ")
    print(f"Agent: {response3}")

# è¿è¡Œç¤ºä¾‹
# asyncio.run(test_conversational_agent())
```

## ğŸ“ æ€»ç»“

Agentæ¶æ„è®¾è®¡æ˜¯æ„å»ºæ™ºèƒ½ç³»ç»Ÿçš„æ ¸å¿ƒï¼Œæœ¬æ–‡æ¡£ä»‹ç»äº†ä»åŸºç¡€æ¶æ„åˆ°å®Œæ•´å®ç°çš„å„ä¸ªæ–¹é¢ã€‚

### ğŸ¯ å…³é”®è¦ç‚¹
- **åˆ†å±‚æ¶æ„**: æ„ŸçŸ¥-æ¨ç†-è§„åˆ’-æ‰§è¡Œçš„å®Œæ•´å¾ªç¯
- **å¤šæ¨¡æ€æ„ŸçŸ¥**: æ”¯æŒæ–‡æœ¬ã€å›¾åƒç­‰å¤šç§è¾“å…¥
- **æ··åˆæ¨ç†**: ç»“åˆè§„åˆ™å’Œç¥ç»ç½‘ç»œçš„ä¼˜åŠ¿
- **è®°å¿†ç³»ç»Ÿ**: åˆ†å±‚è®°å¿†æ¶æ„æ”¯æŒé•¿æœŸå­¦ä¹ 
- **è§„åˆ’ä¼˜åŒ–**: æ™ºèƒ½çš„ä»»åŠ¡è§„åˆ’å’Œæ‰§è¡Œä¼˜åŒ–

### ğŸš€ ä¸‹ä¸€æ­¥
- å­¦ä¹ [è®°å¿†ç³»ç»Ÿè®¾è®¡](02-è®°å¿†ç³»ç»Ÿ.md)
- äº†è§£[å·¥å…·è°ƒç”¨ç³»ç»Ÿ](03-å·¥å…·è°ƒç”¨.md)
- æŒæ¡[RAGé›†æˆAgent](04-RAGç³»ç»Ÿ.md)
- æ¢ç´¢[ä¸Šä¸‹æ–‡ç®¡ç†](05-ä¸Šä¸‹æ–‡ç®¡ç†.md)
