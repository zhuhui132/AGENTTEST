# ğŸ’» AgentæŠ€æœ¯å®ç°æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æ–‡æ¡£æ•´åˆäº†åŸ06ã€07ã€08æ–‡æ¡£çš„æ ¸å¿ƒå†…å®¹ï¼Œæä¾›Agentç³»ç»Ÿçš„å®Œæ•´æŠ€æœ¯å®ç°æ–¹æ¡ˆï¼ŒåŒ…æ‹¬æ¶æ„è®¾è®¡ã€æ ¸å¿ƒæ¨¡å—å®ç°ã€æµ‹è¯•ç­–ç•¥ç­‰ã€‚

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„è®¾è®¡

### å››å±‚æ¶æ„æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç”¨æˆ·äº¤äº’å±‚                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Web UI  â”‚  Mobile App  â”‚  API Gateway  â”‚  ç¬¬ä¸‰æ–¹é›†æˆ      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  Agentæ ¸å¿ƒæœåŠ¡å±‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  æ„å›¾è¯†åˆ«    â”‚ â”‚  å¯¹è¯ç®¡ç†    â”‚ â”‚  ä»»åŠ¡æ‰§è¡Œ    â”‚           â”‚
â”‚  â”‚  æ¨¡å—        â”‚ â”‚  æ¨¡å—        â”‚ â”‚  æ¨¡å—        â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  Agentèƒ½åŠ›å±‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  å¤§è¯­è¨€æ¨¡å‹  â”‚ â”‚  RAGç³»ç»Ÿ     â”‚ â”‚  å·¥å…·é›†æˆ    â”‚           â”‚
â”‚  â”‚  LLM Engine â”‚ â”‚  RAG System  â”‚ â”‚  Tool System â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  åŸºç¡€è®¾æ–½å±‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  å‘é‡æ•°æ®åº“  â”‚ â”‚  å…³ç³»æ•°æ®åº“  â”‚ â”‚  ç¼“å­˜ç³»ç»Ÿ    â”‚           â”‚
â”‚  â”‚  Vector DB  â”‚ â”‚  Relational  â”‚ â”‚  Cache       â”‚           â”‚
â”‚  â”‚             â”‚ â”‚  Database    â”‚ â”‚  System      â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒä¸šåŠ¡æµç¨‹

```mermaid
graph TD
    A[ç”¨æˆ·è¾“å…¥] --> B[æ„å›¾è¯†åˆ«]
    B --> C[ä¸Šä¸‹æ–‡è·å–]
    C --> D[èƒ½åŠ›é€‰æ‹©]
    D --> E{èƒ½åŠ›ç±»å‹}
    E -->|æ¨ç†| F[LLMå¤„ç†]
    E -->|æ£€ç´¢| G[RAGæ£€ç´¢]
    E -->|å·¥å…·| H[å·¥å…·è°ƒç”¨]
    F --> I[ç»“æœæ•´åˆ]
    G --> I
    H --> I
    I --> J[å“åº”è¿”å›]
```

---

## ğŸ› ï¸ æ ¸å¿ƒæ¨¡å—å®ç°

### 1. æ„å›¾è¯†åˆ«æ¨¡å—

#### æŠ€æœ¯æ¡†æ¶
```python
INTENT_RECOGNITION_DEPENDENCIES = {
    "langchain": "0.1.0",           # LLMåº”ç”¨æ¡†æ¶
    "openai": "1.3.0",            # OpenAI API
    "pydantic": "2.4.0",          # æ•°æ®éªŒè¯
    "tiktoken": "0.5.0",           # Tokenè®¡æ•°
    "scikit-learn": "1.3.0",        # æœºå™¨å­¦ä¹ 
}
```

#### æ ¸å¿ƒå®ç°
```python
from fastapi import HTTPException
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import asyncio
import json
import time
import uuid
from datetime import datetime
from langchain.llms import ChatOpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
import tiktoken

class AdvancedIntentRecognitionModule:
    """é«˜çº§æ„å›¾è¯†åˆ«æ¨¡å—å®ç°"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.llm = ChatOpenAI(
            model=config.get("model", "gpt-4"),
            temperature=config.get("temperature", 0.1),
            max_tokens=config.get("max_tokens", 1000),
            api_key=config.get("api_key")
        )

        # æ„å›¾åˆ†ç±»å™¨
        self.intent_classifier = self._build_intent_classifier()

        # å®ä½“æå–å™¨
        self.entity_extractor = self._build_entity_extractor()

        # æ„å›¾æ¨¡æ¿
        self.intent_templates = {
            "query": {
                "description": "ç”¨æˆ·æŸ¥è¯¢ç±»æ„å›¾",
                "keywords": ["æŸ¥è¯¢", "æœç´¢", "æ‰¾", "ä»€ä¹ˆæ˜¯", "å¦‚ä½•", "æ€ä¹ˆ"],
                "examples": ["ä»€ä¹ˆæ˜¯Python", "å¦‚ä½•å­¦ä¹ æœºå™¨å­¦ä¹ ", "æŸ¥è¯¢å¤©æ°”ä¿¡æ¯"]
            },
            "task": {
                "description": "ä»»åŠ¡æ‰§è¡Œç±»æ„å›¾",
                "keywords": ["æ‰§è¡Œ", "å®Œæˆ", "åš", "å¤„ç†", "ç”Ÿæˆ", "åˆ›å»º"],
                "examples": ["å¸®æˆ‘å†™ä¸€ä¸ªPythonå‡½æ•°", "æ‰§è¡Œæ•°æ®åˆ†æ", "åˆ›å»ºä¸€ä¸ªå›¾è¡¨"]
            },
            "conversation": {
                "description": "å¯¹è¯äº¤äº’ç±»æ„å›¾",
                "keywords": ["ä½ å¥½", "è°¢è°¢", "å†è§", "èŠèŠå¤©", "é—²èŠ"],
                "examples": ["ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”ä¸é”™", "è°¢è°¢ä½ çš„å¸®åŠ©", "å†è§"]
            },
            "help": {
                "description": "å¸®åŠ©è¯·æ±‚ç±»æ„å›¾",
                "keywords": ["å¸®åŠ©", "æŒ‡å¯¼", "æ•™ç¨‹", "æ€ä¹ˆç”¨", "åŠŸèƒ½"],
                "examples": ["å¦‚ä½•ä½¿ç”¨è¿™ä¸ªåŠŸèƒ½", "è¯·å¸®åŠ©æˆ‘", "æœ‰ä»€ä¹ˆåŠŸèƒ½"]
            },
            "unknown": {
                "description": "æœªçŸ¥æ„å›¾",
                "keywords": [],
                "examples": []
            }
        }

        # æ€§èƒ½ç›‘æ§
        self.metrics = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "average_processing_time": 0.0,
            "intent_distribution": {}
        }

        # ç¼“å­˜
        self.intent_cache = {}
        self.cache_ttl = config.get("cache_ttl", 3600)  # 1å°æ—¶

    async def recognize(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ„å›¾è¯†åˆ«"""
        start_time = time.time()

        try:
            # æ›´æ–°æŒ‡æ ‡
            self.metrics["total_requests"] += 1

            # æ£€æŸ¥ç¼“å­˜
            cache_key = self._generate_cache_key(request)
            cached_result = self._get_cached_result(cache_key)
            if cached_result:
                return cached_result

            # é¢„å¤„ç†ç”¨æˆ·è¾“å…¥
            processed_input = self._preprocess_input(request.get("message", ""))

            # è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯
            context = self._get_context_info(request)

            # è·å–å¯¹è¯å†å²
            history = self._get_conversation_history(request.get("session_id"))

            # ä½¿ç”¨LLMè¿›è¡Œæ„å›¾åˆ†ç±»
            intent_result = await self._classify_intent_with_llm(processed_input, context, history)

            # ä½¿ç”¨LLMè¿›è¡Œå®ä½“æå–
            entities = await self._extract_entities_with_llm(processed_input, intent_result["intent"])

            # åå¤„ç†å’ŒéªŒè¯
            validated_result = self._validate_and_postprocess(intent_result, entities, request)

            # æ„å»ºæœ€ç»ˆç»“æœ
            final_result = {
                "intent": validated_result["intent"],
                "confidence": validated_result["confidence"],
                "entities": validated_result["entities"],
                "description": validated_result["description"],
                "reasoning": validated_result["reasoning"],
                "processing_time": time.time() - start_time,
                "timestamp": datetime.now().isoformat()
            }

            # ç¼“å­˜ç»“æœ
            self._cache_result(cache_key, final_result)

            # æ›´æ–°æˆåŠŸæŒ‡æ ‡
            self.metrics["successful_requests"] += 1
            self._update_intent_distribution(validated_result["intent"])

            return final_result

        except Exception as e:
            # æ›´æ–°å¤±è´¥æŒ‡æ ‡
            self.metrics["failed_requests"] += 1

            return {
                "intent": "unknown",
                "confidence": 0.0,
                "entities": [],
                "description": f"æ„å›¾è¯†åˆ«å¤±è´¥: {str(e)}",
                "reasoning": "ç³»ç»Ÿé”™è¯¯",
                "processing_time": time.time() - start_time,
                "timestamp": datetime.now().isoformat()
            }
```

### 2. å¯¹è¯ç®¡ç†æ¨¡å—

#### æŠ€æœ¯æ¡†æ¶
```python
CONVERSATION_DEPENDENCIES = {
    "redis": "4.5.0",                # Redisç¼“å­˜å’Œä¼šè¯å­˜å‚¨
    "sqlalchemy": "2.0.0",          # æ•°æ®åº“ORM
    "asyncpg": "0.28.0",             # PostgreSQLå¼‚æ­¥é©±åŠ¨
    "psycopg2-binary": "2.9.0",     # PostgreSQLé©±åŠ¨
    "aiosmtplib": "3.8.0",          # å¼‚æ­¥SMTP
    "jinja2": "3.1.0",               # æ¨¡æ¿å¼•æ“
}
```

#### æ ¸å¿ƒå®ç°
```python
import redis.asyncio as redis
import asyncio
import json
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker

class AdvancedConversationManager:
    """é«˜çº§å¯¹è¯ç®¡ç†å™¨å®ç°"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config

        # Redisè¿æ¥ï¼ˆç¼“å­˜å’Œå¿«é€Ÿå­˜å‚¨ï¼‰
        self.redis_client = None
        self._init_redis_client()

        # æ•°æ®åº“è¿æ¥ï¼ˆæŒä¹…åŒ–å­˜å‚¨ï¼‰
        self.db_engine = None
        self.db_session_factory = None
        self._init_database_client()

        # é…ç½®å‚æ•°
        self.max_conversation_length = config.get("max_conversation_length", 100)
        self.conversation_timeout = config.get("conversation_timeout", 86400)  # 24å°æ—¶
        self.context_window_size = config.get("context_window_size", 20)

        # å†…å­˜ç®¡ç†
        self.memory_usage = {
            "conversations_count": 0,
            "messages_count": 0,
            "cache_size": 0
        }

    async def create_conversation(self, user_id: str, title: Optional[str] = None,
                              initial_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """åˆ›å»ºæ–°çš„å¯¹è¯ä¼šè¯"""
        try:
            # æ£€æŸ¥ç”¨æˆ·å¯¹è¯æ•°é‡é™åˆ¶
            user_conversation_count = await self._get_user_conversation_count(user_id)
            if user_conversation_count >= self.user_conversation_limits["max_conversations_per_user"]:
                raise ValueError(f"ç”¨æˆ· {user_id} å·²è¾¾åˆ°æœ€å¤§å¯¹è¯æ•°é‡é™åˆ¶")

            conversation_id = str(uuid.uuid4())
            session_id = str(uuid.uuid4())
            current_time = datetime.now()
            expires_at = current_time + timedelta(seconds=self.conversation_timeout)

            # åˆ›å»ºå¯¹è¯å¯¹è±¡
            conversation = {
                "conversation_id": conversation_id,
                "session_id": session_id,
                "user_id": user_id,
                "status": "active",
                "title": title,
                "metadata": initial_context or {},
                "created_at": current_time.isoformat(),
                "expires_at": expires_at.isoformat()
            }

            # ä¿å­˜åˆ°æ•°æ®åº“
            await self._save_conversation_to_db(conversation)

            # ç¼“å­˜å¯¹è¯ä¿¡æ¯
            await self._cache_conversation_info(conversation_id, conversation)

            # æ›´æ–°å†…å­˜ä½¿ç”¨ç»Ÿè®¡
            self.memory_usage["conversations_count"] += 1

            return conversation

        except Exception as e:
            logger.error(f"Failed to create conversation: {str(e)}")
            raise

    async def add_message(self, conversation_id: str, user_id: str, role: str,
                        content: str, message_type: str = "text",
                        metadata: Optional[Dict[str, Any]] = None,
                        parent_id: Optional[str] = None) -> Dict[str, Any]:
        """æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯"""
        try:
            # éªŒè¯å¯¹è¯å­˜åœ¨ä¸”æœ‰æ•ˆ
            conversation = await self._get_conversation(conversation_id)
            if not conversation:
                raise ValueError(f"å¯¹è¯ {conversation_id} ä¸å­˜åœ¨")

            # åˆ›å»ºæ¶ˆæ¯å¯¹è±¡
            message = {
                "message_id": str(uuid.uuid4()),
                "conversation_id": conversation_id,
                "user_id": user_id,
                "role": role,
                "content": content,
                "message_type": message_type,
                "metadata": metadata or {},
                "parent_id": parent_id,
                "timestamp": datetime.now().isoformat(),
                "processing_time": 0,
                "token_count": len(content.split())
            }

            # ä¿å­˜åˆ°æ•°æ®åº“
            await self._save_message_to_db(message)

            # æ›´æ–°å¯¹è¯ä¿¡æ¯
            await self._update_conversation_metadata(conversation_id, {
                "last_message_at": datetime.now().isoformat()
            })

            # ç¼“å­˜æœ€æ–°æ¶ˆæ¯
            await self._cache_recent_messages(conversation_id)

            # æ›´æ–°å†…å­˜ä½¿ç”¨ç»Ÿè®¡
            self.memory_usage["messages_count"] += 1

            return message

        except Exception as e:
            logger.error(f"Failed to add message: {str(e)}")
            raise
```

---

## ğŸ§ª æµ‹è¯•å®ç°ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

#### æ„å›¾è¯†åˆ«æ¨¡å—æµ‹è¯•
```python
import pytest
from unittest.mock import Mock, patch, AsyncMock
import json
from datetime import datetime

class TestIntentRecognitionModule:
    """æ„å›¾è¯†åˆ«æ¨¡å—å•å…ƒæµ‹è¯•"""

    @pytest.fixture
    def config(self):
        return {
            "model": "gpt-3.5-turbo",
            "temperature": 0.1,
            "max_tokens": 500,
            "api_key": "test-api-key",
            "cache_ttl": 3600
        }

    @pytest.fixture
    def intent_module(self, config):
        with patch('src.intent_recognition.ChatOpenAI') as mock_llm:
            mock_llm.return_value = Mock()
            return AdvancedIntentRecognitionModule(config)

    @pytest.mark.unit
    @pytest.mark.asyncio
    async def test_recognize_query_intent(self, intent_module):
        """æµ‹è¯•æŸ¥è¯¢ç±»æ„å›¾è¯†åˆ«"""
        mock_response = {
            "intent": "query",
            "confidence": 0.9,
            "reasoning": "ç”¨æˆ·æƒ³æŸ¥è¯¢Pythonç¼–ç¨‹è¯­è¨€çš„ä¿¡æ¯",
            "keywords": ["Python", "ç¼–ç¨‹", "è¯­è¨€"],
            "entities": [
                {
                    "text": "Python",
                    "label": "TECHNOLOGY",
                    "confidence": 0.95
                }
            ]
        }

        intent_module.intent_classifier.arun_async.return_value = json.dumps(mock_response)

        request = {
            "message": "ä»€ä¹ˆæ˜¯Pythonç¼–ç¨‹è¯­è¨€ï¼Ÿ",
            "user_id": "test_user_001",
            "session_id": "session_001"
        }

        result = await intent_module.recognize(request)

        assert result["intent"] == "query"
        assert result["confidence"] == 0.9
        assert len(result["entities"]) == 1
        assert result["processing_time"] > 0
```

### 2. é›†æˆæµ‹è¯•

#### æ•°æ®åº“é›†æˆæµ‹è¯•
```python
import pytest
from testcontainers.postgres import PostgresContainer
from src.conversation_manager import AdvancedConversationManager

class TestConversationIntegration:
    """å¯¹è¯ç®¡ç†æ¨¡å—é›†æˆæµ‹è¯•"""

    @pytest.fixture(scope="class")
    def postgres_container(self):
        with PostgresContainer("postgres:15") as postgres:
            yield postgres

    @pytest.fixture
    def conversation_manager(self, postgres_container):
        config = {
            "database_url": postgres_container.get_connection_url(),
            "redis_host": "localhost",
            "redis_port": 6379,
            "max_conversation_length": 50,
            "conversation_timeout": 3600
        }
        return AdvancedConversationManager(config)

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_conversation_lifecycle(self, conversation_manager):
        """æµ‹è¯•å¯¹è¯å®Œæ•´ç”Ÿå‘½å‘¨æœŸ"""
        user_id = "test_user_001"

        # 1. åˆ›å»ºå¯¹è¯
        conversation = await conversation_manager.create_conversation(
            user_id=user_id,
            title="æµ‹è¯•å¯¹è¯"
        )

        conversation_id = conversation["conversation_id"]
        assert conversation_id is not None
        assert conversation["user_id"] == user_id
        assert conversation["status"] == "active"

        # 2. æ·»åŠ å¤šæ¡æ¶ˆæ¯
        messages = [
            {"role": "user", "content": "ä½ å¥½"},
            {"role": "assistant", "content": "æ‚¨å¥½ï¼å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡"},
            {"role": "user", "content": "å¸®æˆ‘æŸ¥è¯¢å¤©æ°”"}
        ]

        message_ids = []
        for i, msg in enumerate(messages):
            message = await conversation_manager.add_message(
                conversation_id=conversation_id,
                user_id=user_id,
                role=msg["role"],
                content=msg["content"]
            )
            message_ids.append(message["message_id"])

        # 3. è·å–å¯¹è¯ä¸Šä¸‹æ–‡
        context = await conversation_manager.get_conversation_context(conversation_id)
        assert context["conversation_id"] == conversation_id
        assert len(context["messages"]) == len(messages)
```

### 3. æ€§èƒ½æµ‹è¯•

#### è´Ÿè½½æµ‹è¯•æ¡†æ¶
```python
import asyncio
import aiohttp
import time
import statistics
from typing import Dict, List, Any
from dataclasses import dataclass

class PerformanceTestFramework:
    """æ€§èƒ½æµ‹è¯•æ¡†æ¶"""

    def __init__(self, base_url: str):
        self.base_url = base_url
        self.session = None
        self.results = {}

    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()

    async def execute_load_test(self, concurrent_users: int, duration: int) -> Dict[str, Any]:
        """æ‰§è¡Œè´Ÿè½½æµ‹è¯•"""
        results = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "response_times": [],
            "errors": []
        }

        start_time = time.time()
        end_time = start_time + duration

        async def worker_worker(worker_id: int):
            while time.time() < end_time:
                try:
                    request_start = time.time()

                    async with self.session.post(
                        f"{self.base_url}/api/conversations",
                        json={"user_id": f"user_{worker_id}"}
                    ) as response:
                        request_end = time.time()
                        response_time = request_end - request_start

                        if response.status < 400:
                            results["successful_requests"] += 1
                            results["response_times"].append(response_time)
                        else:
                            results["failed_requests"] += 1

                        results["total_requests"] += 1

                except Exception as e:
                    results["failed_requests"] += 1
                    results["total_requests"] += 1
                    results["errors"].append(str(e))

                await asyncio.sleep(0.1)  # çŸ­æš‚ä¼‘æ¯

        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = []
        for i in range(concurrent_users):
            task = asyncio.create_task(worker_worker(i))
            tasks.append(task)

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        await asyncio.gather(*tasks, return_exceptions=True)

        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        if results["response_times"]:
            results["performance"] = {
                "avg_response_time": statistics.mean(results["response_times"]),
                "p95_response_time": statistics.quantiles(results["response_times"], [0.95])[0],
                "p99_response_time": statistics.quantiles(results["response_times"], [0.99])[0],
                "throughput": results["successful_requests"] / duration
            }

        return results

class TestPerformanceLoadTesting:
    """æ€§èƒ½è´Ÿè½½æµ‹è¯•"""

    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_api_performance_under_normal_load(self):
        """æµ‹è¯•APIæ­£å¸¸è´Ÿè½½æ€§èƒ½"""
        base_url = "http://localhost:8000"

        async with PerformanceTestFramework(base_url) as framework:
            result = await framework.execute_load_test(
                concurrent_users=50,
                duration=60
            )

            # éªŒè¯æ€§èƒ½æŒ‡æ ‡
            assert result["successful_requests"] / result["total_requests"] > 0.95
            assert result["performance"]["p95_response_time"] < 2.0
            assert result["performance"]["throughput"] > 10
```

---

## ğŸ“Š è´¨é‡ä¿è¯

### æµ‹è¯•è¦†ç›–
- **å•å…ƒæµ‹è¯•**: è¦†ç›–æ‰€æœ‰æ ¸å¿ƒæ¨¡å—
- **é›†æˆæµ‹è¯•**: éªŒè¯ç»„ä»¶é—´äº¤äº’
- **æ€§èƒ½æµ‹è¯•**: ç¡®ä¿å“åº”æ—¶é—´è¦æ±‚
- **ç«¯åˆ°ç«¯æµ‹è¯•**: éªŒè¯å®Œæ•´ä¸šåŠ¡æµç¨‹

### æ€§èƒ½æŒ‡æ ‡
- **å“åº”æ—¶é—´**: P95 < 2ç§’
- **ååé‡**: > 50 req/s
- **æˆåŠŸç‡**: > 95%
- **å¹¶å‘æ”¯æŒ**: > 100ç”¨æˆ·

### ä»£ç è´¨é‡
- **ä»£ç è¦†ç›–ç‡**: > 80%
- **ä»£ç è§„èŒƒ**: éµå¾ªPEP 8
- **ç±»å‹æ£€æŸ¥**: ä½¿ç”¨mypy
- **å®‰å…¨æ£€æŸ¥**: ä½¿ç”¨bandit

---

## ğŸš€ éƒ¨ç½²æŒ‡å—

### ç¯å¢ƒè¦æ±‚
- Python 3.9+
- PostgreSQL 13+
- Redis 6+
- FastAPI
- Docker (å¯é€‰)

### é…ç½®ç®¡ç†
```python
# config/production.py
PRODUCTION_CONFIG = {
    "database_url": "postgresql://user:password@localhost/agent_db",
    "redis_url": "redis://localhost:6379/0",
    "api_keys": {
        "openai": "your-openai-api-key",
        "anthropic": "your-anthropic-api-key"
    },
    "performance": {
        "max_concurrent_requests": 1000,
        "request_timeout": 30,
        "cache_ttl": 3600
    }
}
```

### Dockeréƒ¨ç½²
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY src/ ./src/
COPY config/ ./config/

EXPOSE 8000
CMD ["uvicorn", "src.api:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

*æ–‡æ¡£æŒç»­æ›´æ–°ï¼Œæ¬¢è¿è´¡çŒ®å’Œåé¦ˆ*
*æœ€åæ›´æ–°æ—¶é—´: 2025-11-05*
*ç‰ˆæœ¬: v3.0.0*
