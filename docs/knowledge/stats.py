#!/usr/bin/env python3
"""
çŸ¥è¯†åº“ç»Ÿè®¡è„šæœ¬
"""

import os
import re
from pathlib import Path

def count_code_blocks(file_path):
    """ç»Ÿè®¡ä»£ç å—æ•°é‡"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            # ç»Ÿè®¡ä»£ç å—ï¼ˆ```python æˆ– ```ï¼‰
            code_blocks = len(re.findall(r'```python', content))
            return code_blocks
    except:
        return 0

def count_word_count(file_path):
    """ç»Ÿè®¡å­—æ•°"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            # ç§»é™¤ä»£ç å—åå†ç»Ÿè®¡ä¸­æ–‡å­—æ•°
            content_no_code = re.sub(r'```[\s\S]*?```', '', content)
            chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', content_no_code))
            return chinese_chars
    except:
        return 0

def analyze_knowledge_base():
    """åˆ†æçŸ¥è¯†åº“ç»“æ„"""
    knowledge_dir = Path('.')

    stats = {
        'categories': {},
        'total_files': 0,
        'total_code_blocks': 0,
        'total_words': 0
    }

    # éå†æ‰€æœ‰ç›®å½•
    for category_dir in knowledge_dir.iterdir():
        if category_dir.is_dir() and category_dir.name not in ['.', '__pycache__']:
            category_name = category_dir.name
            category_stats = {
                'files': 0,
                'code_blocks': 0,
                'words': 0,
                'file_list': []
            }

            # éå†ç›®å½•ä¸­çš„æ–‡ä»¶
            for file_path in category_dir.glob('*.md'):
                if file_path.is_file():
                    category_stats['files'] += 1
                    code_blocks = count_code_blocks(file_path)
                    words = count_word_count(file_path)

                    category_stats['code_blocks'] += code_blocks
                    category_stats['words'] += words
                    category_stats['file_list'].append(file_path.name)

                    stats['total_code_blocks'] += code_blocks
                    stats['total_words'] += words

            stats['categories'][category_name] = category_stats
            stats['total_files'] += category_stats['files']

    return stats

def print_statistics(stats):
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    print("ğŸ“š AIçŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 50)
    print(f"ğŸ“ æ€»åˆ†ç±»æ•°: {len(stats['categories'])}")
    print(f"ğŸ“„ æ€»æ–‡æ¡£æ•°: {stats['total_files']}")
    print(f"ğŸ’» ä»£ç ç¤ºä¾‹æ•°: {stats['total_code_blocks']}")
    print(f"ğŸ“ æ€»ä¸­æ–‡å­—æ•°: {stats['total_words']:,}")
    print()

    print("ğŸ“‹ å„åˆ†ç±»ç»Ÿè®¡:")
    print("-" * 50)

    for category, data in stats['categories'].items():
        print(f"ğŸ—‚ï¸ {category}")
        print(f"   ğŸ“„ æ–‡æ¡£æ•°: {data['files']}")
        print(f"   ğŸ’» ä»£ç ç¤ºä¾‹: {data['code_blocks']}")
        print(f"   ğŸ“ ä¸­æ–‡å­—æ•°: {data['words']:,}")

        if data['file_list']:
            print(f"   ğŸ“‹ æ–‡æ¡£åˆ—è¡¨:")
            for file in sorted(data['file_list']):
                print(f"      - {file}")
        print()

    print("ğŸ¯ ä¸»è¦æŠ€æœ¯è¦†ç›–:")
    print("-" * 50)

    # æŠ€æœ¯é¢†åŸŸç»Ÿè®¡
    tech_areas = {
        'machine-learning': 'æœºå™¨å­¦ä¹ ',
        'deep-learning': 'æ·±åº¦å­¦ä¹ ',
        'llm': 'å¤§è¯­è¨€æ¨¡å‹',
        'agents': 'æ™ºèƒ½Agent',
        'reinforcement-learning': 'å¼ºåŒ–å­¦ä¹ ',
        'multimodal': 'å¤šæ¨¡æ€å­¦ä¹ ',
        'rag': 'æ£€ç´¢å¢å¼ºç”Ÿæˆ',
        'deployment': 'æ¨¡å‹éƒ¨ç½²',
        'security': 'å®‰å…¨ä¸ä¼¦ç†',
        'trends': 'å‰æ²¿æŠ€æœ¯'
    }

    for tech_key, tech_name in tech_areas.items():
        if tech_key in stats['categories']:
            data = stats['categories'][tech_key]
            print(f"  ğŸ“– {tech_name}: {data['files']}ä¸ªæ–‡æ¡£, {data['code_blocks']}ä¸ªä»£ç ç¤ºä¾‹")

def generate_index_content(stats):
    """ç”Ÿæˆç›®å½•å†…å®¹"""
    content = """# ğŸ“š AIçŸ¥è¯†åº“å®æ—¶ç»Ÿè®¡

## ğŸ“Š æ€»ä½“ç»Ÿè®¡

| æŒ‡æ ‡ | æ•°é‡ |
|------|------|
| åˆ†ç±»æ•°é‡ | {total_categories} |
| æ–‡æ¡£æ€»æ•° | {total_files} |
| ä»£ç ç¤ºä¾‹ | {total_code_blocks} |
| ä¸­æ–‡å­—æ•° | {total_words:,} |

## ğŸ“‹ åˆ†ç±»è¯¦æƒ…

| åˆ†ç±» | æ–‡æ¡£æ•° | ä»£ç ç¤ºä¾‹ | å­—æ•° |
|------|--------|----------|------|
""".format(
        total_categories=len(stats['categories']),
        total_files=stats['total_files'],
        total_code_blocks=stats['total_code_blocks'],
        total_words=stats['total_words']
    )

    for category, data in stats['categories'].items():
        category_names = {
            'machine-learning': 'æœºå™¨å­¦ä¹ ',
            'deep-learning': 'æ·±åº¦å­¦ä¹ ',
            'llm': 'å¤§è¯­è¨€æ¨¡å‹',
            'agents': 'æ™ºèƒ½Agent',
            'reinforcement-learning': 'å¼ºåŒ–å­¦ä¹ ',
            'multimodal': 'å¤šæ¨¡æ€å­¦ä¹ ',
            'rag': 'æ£€ç´¢å¢å¼ºç”Ÿæˆ',
            'deployment': 'æ¨¡å‹éƒ¨ç½²',
            'security': 'å®‰å…¨ä¸ä¼¦ç†',
            'trends': 'å‰æ²¿æŠ€æœ¯'
        }

        category_name = category_names.get(category, category)
        content += f"| {category_name} | {data['files']} | {data['code_blocks']} | {data['words']:,} |\n"

    content += """

## ğŸ“ˆ æ›´æ–°è®°å½•

- `last_update`: è‡ªåŠ¨ç”Ÿæˆ
- `version`: v3.0.0
- `status`: æ´»è·ƒæ›´æ–°ä¸­

---

*æ­¤ç»Ÿè®¡ç”±è„šæœ¬è‡ªåŠ¨ç”Ÿæˆï¼Œåæ˜ å½“å‰çŸ¥è¯†åº“çŠ¶æ€* ğŸš€
"""

    return content

if __name__ == "__main__":
    print("æ­£åœ¨åˆ†æçŸ¥è¯†åº“ç»“æ„...")
    stats = analyze_knowledge_base()

    print_statistics(stats)

    # ç”Ÿæˆç»Ÿè®¡æ–‡æ¡£
    stats_content = generate_index_content(stats)
    with open('statistics.md', 'w', encoding='utf-8') as f:
        f.write(stats_content)

    print("\nğŸ“„ ç»Ÿè®¡æ–‡æ¡£å·²ç”Ÿæˆ: statistics.md")
    print("ğŸš€ çŸ¥è¯†åº“åˆ†æå®Œæˆï¼")
